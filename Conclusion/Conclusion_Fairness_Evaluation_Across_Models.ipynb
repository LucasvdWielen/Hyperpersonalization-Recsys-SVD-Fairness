{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Metrics Comparison and Discussion\n",
    "\n",
    "#### Comparison of Fairness Across Datasets\n",
    "\n",
    "We evaluate the fairness of the recommendation models (**SVD++**, **UserKNN**, and **ItemKNN**) on two distinct datasets: **MovieLens** and **Yelp**, using a comprehensive set of fairness metrics. While both datasets support recommender system research, they differ in scope, structure, and granularity. Please see the results at the end of this Notebook.\n",
    "\n",
    "**Dataset Differences**:\n",
    "\n",
    "- **MovieLens** is a structured dataset with explicit ratings, clear user demographics (gender, age, occupation), and consistent rating behavior, making it highly suitable for recommender system evaluation.\n",
    "- **Yelp** consists of unstructured reviews and business metadata, offering fewer user demographics. Additionally, the domain difference (movies vs. local businesses) may impact recommendation behavior and fairness interpretation.\n",
    "- For **Yelp**, fairness metrics were computed using only a subset of **50 users** due to **computational constraints**. Ideally, this analysis would include at least **500 users** for more robust results.\n",
    "- In practice, **e-commerce** platforms may be more comparable to MovieLens in terms of structure and item categorization, whereas Yelp represents a broader and more diverse set of user preferences and item types.\n",
    "\n",
    "\n",
    "\n",
    "#### Key Metric Observations\n",
    "\n",
    "| Metric                         | MovieLens Insights                                              | Yelp Insights                                                   |\n",
    "|-------------------------------|------------------------------------------------------------------|------------------------------------------------------------------|\n",
    "| **RMSE (Accuracy)**           | SVD++ is most accurate (0.9287); ItemKNN and UserKNN higher.     | Similar ranking, but overall higher RMSE (lower accuracy).       |\n",
    "| **Gender-Based RMSE**         | RMSE is consistently **higher for female users** across models, suggesting gender-based bias or data imbalance. | Gender split less detailed, but similar trend present.           |\n",
    "| **Counterfactual Difference** | All models sensitive to gender flips (~0.0798), reflecting potential fairness concerns. | Similar magnitude observed for UserKNN (0.0756).                 |\n",
    "| **Consistency**               | Highest for UserKNN and SVD++; ItemKNN slightly lower.           | UserKNN shows strong consistency (0.297), possibly due to domain diversity. |\n",
    "| **Statistical Parity**        | Fair exposure with low parity gaps (e.g., 0.0154 for ItemKNN).   | Parity slightly lower (e.g., 0.0678), suggesting balanced exposure. |\n",
    "| **Rawlsian Min Exposure**     | SVD++ ensures better exposure for lowest-represented group.      | UserKNN has stronger Rawlsian score (0.7407), indicating equitable coverage. |\n",
    "| **Local Individual Fairness** | ItemKNN scores high (0.9491), indicating minimal deviation between similar users. | SVD++ also strong (0.2267), despite complex domain.             |\n",
    "| **Calibration Error**         | Best for SVD++; ItemKNN higher error suggests over/underconfidence in predictions. | Similar trend.                                                  |\n",
    "| **Disparate Impact Ratio**    | Close to 1 across models, indicating fairness in exposure likelihood. | Stable and fair ratio across models (e.g., SVD++: 1.0078).       |\n",
    "| **Demographic Parity**        | Generally low (<0.02), showing fair recommendation distribution. | Consistent, with lowest parity gap from UserKNN (0.0549).        |\n",
    "\n",
    "\n",
    "\n",
    "### Discussion\n",
    "\n",
    "The MovieLens dataset proves to be more suitable for rigorous recommender system evaluation due to its well-structured format, the availability of explicit ratings, and comprehensive demographic features. These elements make it easier to analyze model behavior and interpret fairness outcomes systematically. In contrast, the Yelp dataset, which is based on unstructured review data and contains fewer demographic attributes, introduces additional complexity. The domain-specific behavior associated with Yelp, such as evaluating restaurants or services, leads to greater noise and variability in user interactions, which may obscure fairness patterns.\n",
    "\n",
    "A recurring theme across models and datasets is the impact of gender on fairness. Female users often appear to have fewer interactions or narrower rating distributions compared to male users. This can reduce the system's ability to learn robust user preferences, resulting in less accurate recommendations and lower exposure. These discrepancies are reflected in fairness metrics like RMSE, statistical parity, and disparate impact ratio, which tend to reveal slightly higher bias toward male users.\n",
    "\n",
    "The differences in scores between the datasets, especially in metrics like Local Individual Fairness, can be attributed to the nature of the domains themselves. MovieLens users engage with a shared and universal set of items/movies that are more broadly rated and consumed across user groups. This leads to more consistent behavior and better alignment between similar users. In contrast, Yelp users may vary significantly in the types of businesses they interact with, introducing sparsity and limiting the effectiveness of neighborhood-based models like KNN.\n",
    "\n",
    "Model design also plays a key role in observed fairness. SVD++, being a model-based approach, typically exhibits stronger calibration and consistency. It generalizes better in sparse conditions and avoids some of the pitfalls seen in neighbor-based methods. Meanwhile, memory-based models such as UserKNN and ItemKNN are more sensitive to the density and quality of historical data, which can negatively affect both fairness and accuracy in noisier datasets.\n",
    "\n",
    "One notable limitation in the Yelp evaluation is the sample size. Fairness metrics were calculated using only 50 users due to computational and time constraints. A larger sample, ideally 500 users or more, would be necessary for stronger statistical confidence and a more representative fairness assessment. This smaller scale likely contributes to higher variability in some metrics and limits the ability to generalize results.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Among the three models, SVD++ demonstrates the best overall balance between predictive accuracy and fairness, performing consistently well across both datasets. ItemKNN shows strong performance in local individual fairness, especially in MovieLens, where user-item interactions are richer and more structured. In contrast, UserKNN yields the best consistency and Rawlsian exposure scores on Yelp, indicating its strength in treating similar users equitably and covering disadvantaged groups more evenly.\n",
    "\n",
    "Gender-related disparities persist across both datasets, reinforcing the importance of integrating fairness-aware design into recommendation pipelines. While all models exhibit some sensitivity to gender-based differences, the effects are most pronounced in sparse or demographically unbalanced data.\n",
    "\n",
    "Ultimately, the structure and richness of the dataset play a critical role in how fairness is expressed and measured. MovieLens, with its high-quality data and balanced design, is better suited for fairness research and recommendation system evaluation than Yelp. As fairness in machine learning continues to grow in importance, choosing the right dataset is just as crucial as choosing the right model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Across Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fairness Table (Movielens):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LucasvanderWielenAlp\\AppData\\Local\\Temp\\ipykernel_27932\\996378716.py:25: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  formatted_table = condensed_transposed.copy().applymap(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ItemKNN",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "UserKNN",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SVD++",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d76debd2-387e-422c-839b-62f1a0327b3f",
       "rows": [
        [
         "RMSE",
         "0.9738",
         "1.0126",
         "0.9287"
        ],
        [
         "RMSE (Male)",
         "0.9634",
         "0.9855",
         "0.9139"
        ],
        [
         "RMSE (Female)",
         "1.0031",
         "1.0869",
         "0.9699"
        ],
        [
         "CFD (Gender)",
         "0.0798",
         "0.0798",
         "0.0799"
        ],
        [
         "Consistency",
         "0.2520",
         "0.2573",
         "0.2580"
        ],
        [
         "Stat. Parity (Gender, T=3.5)",
         "0.0154",
         "0.0023",
         "0.0118"
        ],
        [
         "Rawlsian Exposure (Gender, T=3.5)",
         "0.6690",
         "0.5691",
         "0.5488"
        ],
        [
         "Local Individual Fairness",
         "0.9491",
         "-",
         "-"
        ],
        [
         "Calibration Error",
         "0.7588",
         "-",
         "-"
        ],
        [
         "Disparate Impact Ratio",
         "0.9775",
         "-",
         "-"
        ],
        [
         "Demographic Parity",
         "0.0154",
         "-",
         "-"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 11
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemKNN</th>\n",
       "      <th>UserKNN</th>\n",
       "      <th>SVD++</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9738</td>\n",
       "      <td>1.0126</td>\n",
       "      <td>0.9287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE (Male)</th>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.9139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE (Female)</th>\n",
       "      <td>1.0031</td>\n",
       "      <td>1.0869</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CFD (Gender)</th>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.0799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consistency</th>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stat. Parity (Gender, T=3.5)</th>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rawlsian Exposure (Gender, T=3.5)</th>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.5691</td>\n",
       "      <td>0.5488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Local Individual Fairness</th>\n",
       "      <td>0.9491</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calibration Error</th>\n",
       "      <td>0.7588</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <td>0.9775</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity</th>\n",
       "      <td>0.0154</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ItemKNN UserKNN   SVD++\n",
       "Metric                                                   \n",
       "RMSE                               0.9738  1.0126  0.9287\n",
       "RMSE (Male)                        0.9634  0.9855  0.9139\n",
       "RMSE (Female)                      1.0031  1.0869  0.9699\n",
       "CFD (Gender)                       0.0798  0.0798  0.0799\n",
       "Consistency                        0.2520  0.2573  0.2580\n",
       "Stat. Parity (Gender, T=3.5)       0.0154  0.0023  0.0118\n",
       "Rawlsian Exposure (Gender, T=3.5)  0.6690  0.5691  0.5488\n",
       "Local Individual Fairness          0.9491       -       -\n",
       "Calibration Error                  0.7588       -       -\n",
       "Disparate Impact Ratio             0.9775       -       -\n",
       "Demographic Parity                 0.0154       -       -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Summary Table Across Models (Yelp):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SVD++",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ItemKNN",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "UserKNN",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6d3741a3-2d40-41b6-94e9-b4591cfcf08c",
       "rows": [
        [
         "RMSE",
         "1.0175",
         "1.295",
         "1.3022"
        ],
        [
         "RMSE (Female)",
         "1.0122",
         "1.2768",
         "1.2729"
        ],
        [
         "RMSE (Male)",
         "0.9846",
         "1.3171",
         "1.2726"
        ],
        [
         "RMSE (Unknown)",
         "1.0574",
         "1.3574",
         "1.2959"
        ],
        [
         "Calibration Error",
         "0.7381",
         "0.8946",
         "0.5593"
        ],
        [
         "Local Individual Fairness",
         "0.2267",
         "0.2615",
         "-"
        ],
        [
         "Disparate Impact Ratio",
         "1.0078",
         "1.0194",
         "1.0792"
        ],
        [
         "Demographic Parity",
         "0.0076",
         "0.0174",
         "0.0549"
        ],
        [
         "Counterfactual Difference",
         "-",
         "-",
         "0.0756"
        ],
        [
         "Consistency Score",
         "-",
         "-",
         "0.297"
        ],
        [
         "Statistical Parity",
         "-",
         "-",
         "0.0678"
        ],
        [
         "Rawlsian Min Exposure",
         "-",
         "-",
         "0.7407"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVD++</th>\n",
       "      <th>ItemKNN</th>\n",
       "      <th>UserKNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.0175</td>\n",
       "      <td>1.295</td>\n",
       "      <td>1.3022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE (Female)</th>\n",
       "      <td>1.0122</td>\n",
       "      <td>1.2768</td>\n",
       "      <td>1.2729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE (Male)</th>\n",
       "      <td>0.9846</td>\n",
       "      <td>1.3171</td>\n",
       "      <td>1.2726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE (Unknown)</th>\n",
       "      <td>1.0574</td>\n",
       "      <td>1.3574</td>\n",
       "      <td>1.2959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calibration Error</th>\n",
       "      <td>0.7381</td>\n",
       "      <td>0.8946</td>\n",
       "      <td>0.5593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Local Individual Fairness</th>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact Ratio</th>\n",
       "      <td>1.0078</td>\n",
       "      <td>1.0194</td>\n",
       "      <td>1.0792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demographic Parity</th>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Counterfactual Difference</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consistency Score</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rawlsian Min Exposure</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.7407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            SVD++ ItemKNN UserKNN\n",
       "RMSE                       1.0175   1.295  1.3022\n",
       "RMSE (Female)              1.0122  1.2768  1.2729\n",
       "RMSE (Male)                0.9846  1.3171  1.2726\n",
       "RMSE (Unknown)             1.0574  1.3574  1.2959\n",
       "Calibration Error          0.7381  0.8946  0.5593\n",
       "Local Individual Fairness  0.2267  0.2615       -\n",
       "Disparate Impact Ratio     1.0078  1.0194  1.0792\n",
       "Demographic Parity         0.0076  0.0174  0.0549\n",
       "Counterfactual Difference       -       -  0.0756\n",
       "Consistency Score               -       -   0.297\n",
       "Statistical Parity              -       -  0.0678\n",
       "Rawlsian Min Exposure           -       -  0.7407"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MovieLens fairness metrics table\n",
    "# Build the DataFrame using np.nan for missing metrics\n",
    "condensed_transposed = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'RMSE',\n",
    "        'RMSE (Male)',\n",
    "        'RMSE (Female)',\n",
    "        'CFD (Gender)',\n",
    "        'Consistency',\n",
    "        'Stat. Parity (Gender, T=3.5)',\n",
    "        'Rawlsian Exposure (Gender, T=3.5)',\n",
    "        'Local Individual Fairness',\n",
    "        'Calibration Error',\n",
    "        'Disparate Impact Ratio',\n",
    "        'Demographic Parity'\n",
    "    ],\n",
    "    'ItemKNN': [0.9738, 0.9634, 1.0031, 0.0798, 0.2520, 0.0154, 0.6690, 0.9491, 0.7588, 0.9775, 0.0154],\n",
    "    'UserKNN': [1.0126, 0.9855, 1.0869, 0.0798, 0.2573, 0.0023, 0.5691, np.nan, np.nan, np.nan, np.nan],\n",
    "    'SVD++':  [0.9287, 0.9139, 0.9699, 0.0799, 0.2580, 0.0118, 0.5488, np.nan, np.nan, np.nan, np.nan]\n",
    "})\n",
    "\n",
    "condensed_transposed.set_index('Metric', inplace=True)\n",
    "\n",
    "# Format for display: keep numbers but show '-' for NaNs\n",
    "formatted_table = condensed_transposed.copy().applymap(\n",
    "    lambda x: \"-\" if pd.isna(x) else f\"{x:.4f}\"\n",
    ")\n",
    "\n",
    "# Display\n",
    "print(\"\\n Fairness Table (Movielens):\")\n",
    "display(formatted_table)\n",
    "\n",
    "\n",
    "# Define metrics and model scores as lists\n",
    "metrics = [\n",
    "    \"RMSE\", \"RMSE (Female)\", \"RMSE (Male)\", \"RMSE (Unknown)\",\n",
    "    \"Calibration Error\", \"Local Individual Fairness\",\n",
    "    \"Disparate Impact Ratio\", \"Demographic Parity\",\n",
    "    \"Counterfactual Difference\", \"Consistency Score\",\n",
    "    \"Statistical Parity\", \"Rawlsian Min Exposure\"\n",
    "]\n",
    "\n",
    "svdpp    = [1.0175, 1.0122, 0.9846, 1.0574, 0.7381, 0.2267, 1.0078, 0.0076, \"-\", \"-\", \"-\", \"-\"]\n",
    "itemknn  = [1.295,  1.2768, 1.3171, 1.3574, 0.8946, 0.2615, 1.0194, 0.0174, \"-\", \"-\", \"-\", \"-\"]\n",
    "userknn  = [1.3022, 1.2729, 1.2726, 1.2959, 0.5593, \"-\",    1.0792, 0.0549, 0.0756, 0.297, 0.0678, 0.7407]\n",
    "\n",
    "# Create and format DataFrame\n",
    "fairness_yelp = pd.DataFrame({\n",
    "    'SVD++': svdpp,\n",
    "    'ItemKNN': itemknn,\n",
    "    'UserKNN': userknn\n",
    "}, index=metrics).replace(np.nan, \"-\")\n",
    "\n",
    "# Display the table\n",
    "print(\"\\nFairness Summary Table Across Models (Yelp):\")\n",
    "display(fairness_yelp)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
