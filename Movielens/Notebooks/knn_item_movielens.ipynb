{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Evaluation of UserKNN on the MovieLens 100K Dataset\n",
    "\n",
    "**Course:** System Development for Marketing  \n",
    "**Assignment:** Hyperpersonalization – Recommender Systems  \n",
    "**Model Focus:** Item-based Collaborative Filtering (ItemKNN)  \n",
    "**Dataset:** MovieLens 100K  \n",
    "**Author:** Lucas van der Wielen  \n",
    "**Date:** 04-04-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook presents the implementation and evaluation of an Item-based K-Nearest Neighbors (ItemKNN) recommender system using the MovieLens 100K dataset. ItemKNN is a memory-based collaborative filtering technique that generates recommendations for a user based on items similar to those the user has rated positively.\n",
    "\n",
    "The objectives of this notebook are twofold:\n",
    "\n",
    "1. **Performance Evaluation**: Train and tune the ItemKNN model and assess its accuracy using RMSE (Root Mean Squared Error).\n",
    "2. **Prepare a Dataset for Fairness Evaluation**: Create a general dataset to use for fairness evaluation across the different models\n",
    "\n",
    "Gender is selected as the primary protected attribute to allow for consistent comparison across datasets, including Yelp, which lacks age-related data. Throughout this notebook, we follow a reproducible pipeline that includes data preprocessing, model training, prediction, and evaluation using both accuracy-based and fairness-based metrics.\n",
    "\n",
    "## Datasets needed for this Jupyter Notebook:\n",
    "\n",
    "- `df_full.csv`  \n",
    "  Preprocessed dataset combining ratings and user/item metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Packages\n",
    "In this section, we import the necessary libraries and packages that will be used throughout the code for data manipulation, model building, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id  user_id  rating            timestamp  age gender  occupation  \\\n",
      "0       242      196       3  1997-12-04 15:55:49   49      M      writer   \n",
      "1       302      186       3  1998-04-04 19:22:22   39      F   executive   \n",
      "2       377       22       1  1997-11-07 07:18:36   25      M      writer   \n",
      "3        51      244       2  1997-11-27 05:02:03   28      M  technician   \n",
      "4       346      166       1  1998-02-02 05:33:16   47      M    educator   \n",
      "\n",
      "  zip_code                       title release_date  release_year  \n",
      "0    55105                Kolya (1996)  24-Jan-1997          1997  \n",
      "1    00000    L.A. Confidential (1997)  01-Jan-1997          1997  \n",
      "2    40206         Heavyweights (1994)  01-Jan-1994          1994  \n",
      "3    80525  Legends of the Fall (1994)  01-Jan-1994          1994  \n",
      "4    55113         Jackie Brown (1997)  01-Jan-1997          1997  \n",
      "(99991, 11)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your CSV file\n",
    "file_path = r\"C:\\Users\\LucasvanderWielenAlp\\OneDrive - Alpine Hearing Protection\\Documenten\\Master DDB\\System Development\\Data\\df_full.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df_full = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to check\n",
    "print(df_full.head())\n",
    "print(df_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 943\n",
      "Test users:  943\n",
      "Train movies: 1617\n",
      "Test movies:  1480\n"
     ]
    }
   ],
   "source": [
    "# Create the full user-item matrix\n",
    "user_item_matrix = df_full.pivot_table(index='user_id', columns='movie_id', values='rating')\n",
    "\n",
    "# Create empty train/test matrices\n",
    "train_matrix = user_item_matrix.copy() * np.nan\n",
    "test_matrix = user_item_matrix.copy() * np.nan\n",
    "\n",
    "# User-wise split: 80% train, 20% test\n",
    "for user_id in user_item_matrix.index:\n",
    "    user_ratings = user_item_matrix.loc[user_id].dropna()\n",
    "    if len(user_ratings) < 5:\n",
    "        continue\n",
    "    shuffled = user_ratings.sample(frac=1, random_state=42)\n",
    "    cutoff = int(0.8 * len(shuffled))\n",
    "    train_items = shuffled.iloc[:cutoff]\n",
    "    test_items = shuffled.iloc[cutoff:]\n",
    "\n",
    "    train_matrix.loc[user_id, train_items.index] = train_items.values\n",
    "    test_matrix.loc[user_id, test_items.index] = test_items.values\n",
    "\n",
    "# Convert train/test matrices back to long-format DataFrames\n",
    "df_train = train_matrix.stack().reset_index()\n",
    "df_train.columns = ['user_id', 'movie_id', 'rating']\n",
    "\n",
    "df_test = test_matrix.stack().reset_index()\n",
    "df_test.columns = ['user_id', 'movie_id', 'rating']\n",
    "\n",
    "# Print stats: check user/movie coverage\n",
    "print(\"Train users:\", df_train['user_id'].nunique())\n",
    "print(\"Test users: \", df_test['user_id'].nunique())\n",
    "print(\"Train movies:\", df_train['movie_id'].nunique())\n",
    "print(\"Test movies: \", df_test['movie_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DOUBLE CHECK:\n",
      "Original rating count: 99991\n",
      "Train rating count:    79610\n",
      "Test rating count:     20381\n",
      "Total (train + test):  99991\n",
      "Rating count preserved: True\n",
      "Overlapping ratings in train and test: 0\n",
      "No overlap between train and test: True\n"
     ]
    }
   ],
   "source": [
    "# DOUBLE CHECK – Rating count and overlap validation\n",
    "# Rebuild full matrix from df_full\n",
    "full_matrix = df_full.pivot_table(index='user_id', columns='movie_id', values='rating')\n",
    "\n",
    "# Rebuild train/test matrices from df_train and df_test\n",
    "train_matrix_check = full_matrix.copy() * np.nan\n",
    "test_matrix_check = full_matrix.copy() * np.nan\n",
    "\n",
    "for _, row in df_train.iterrows():\n",
    "    train_matrix_check.loc[row['user_id'], row['movie_id']] = row['rating']\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    test_matrix_check.loc[row['user_id'], row['movie_id']] = row['rating']\n",
    "\n",
    "# Validate counts and overlap\n",
    "original_count = (~full_matrix.isna()).sum().sum()\n",
    "train_count = (~train_matrix_check.isna()).sum().sum()\n",
    "test_count = (~test_matrix_check.isna()).sum().sum()\n",
    "overlap_matrix = (~train_matrix_check.isna()) & (~test_matrix_check.isna())\n",
    "overlap_count = overlap_matrix.sum().sum()\n",
    "\n",
    "print(\"\\nDOUBLE CHECK:\")\n",
    "print(f\"Original rating count: {original_count}\")\n",
    "print(f\"Train rating count:    {train_count}\")\n",
    "print(f\"Test rating count:     {test_count}\")\n",
    "print(f\"Total (train + test):  {train_count + test_count}\")\n",
    "print(\"Rating count preserved:\", original_count == train_count + test_count)\n",
    "print(f\"Overlapping ratings in train and test: {overlap_count}\")\n",
    "print(\"No overlap between train and test:\", overlap_count == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build item-item similarity matrix from df_train\n",
    "train_pivot = df_train.pivot_table(index='user_id', columns='movie_id', values='rating')\n",
    "item_matrix = train_pivot.T.fillna(0)  # Transpose to get item-item structure\n",
    "\n",
    "# Cosine similarity between items\n",
    "item_similarity = cosine_similarity(item_matrix)\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=item_matrix.index, columns=item_matrix.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, RMSE=0.9951\n",
      "k=10, RMSE=0.9748\n",
      "k=15, RMSE=0.9738\n",
      "k=20, RMSE=0.9765\n",
      "k=30, RMSE=0.9830\n",
      "k=50, RMSE=0.9926\n",
      "\n",
      "Best k: 15 with RMSE: 0.9738\n",
      "\n",
      "Final RMSE using best k=15: 0.9738\n"
     ]
    }
   ],
   "source": [
    "# Define prediction function for ItemKNN\n",
    "def predict_rating_itemknn(user_id, movie_id, k):\n",
    "    if movie_id not in item_similarity_df.columns or user_id not in train_pivot.index:\n",
    "        return np.nan\n",
    "\n",
    "    user_ratings = train_pivot.loc[user_id].dropna()\n",
    "    if len(user_ratings) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    sims = item_similarity_df.loc[movie_id, user_ratings.index]\n",
    "    top_k = sims.sort_values(ascending=False).head(k)\n",
    "    top_k_ratings = user_ratings[top_k.index]\n",
    "\n",
    "    if top_k.sum() == 0:\n",
    "        return np.nan\n",
    "\n",
    "    return np.dot(top_k, top_k_ratings) / top_k.sum()\n",
    "\n",
    "# Hyperparameter tuning for k (top-k neighbors)\n",
    "\n",
    "k_values = [5, 10, 15, 20, 30, 50]\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    actual, predicted = [], []\n",
    "\n",
    "    for _, row in df_test.iterrows():\n",
    "        pred = predict_rating_itemknn(row['user_id'], row['movie_id'], k)\n",
    "        if not np.isnan(pred):\n",
    "            actual.append(row['rating'])\n",
    "            predicted.append(pred)\n",
    "\n",
    "    if predicted:\n",
    "        rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "        results.append((k, rmse))\n",
    "        print(f\"k={k}, RMSE={rmse:.4f}\")\n",
    "    else:\n",
    "        print(f\"k={k}, No predictions made.\")\n",
    "\n",
    "# Final test with best k\n",
    "best_k, best_rmse = min(results, key=lambda x: x[1])\n",
    "print(f\"\\nBest k: {best_k} with RMSE: {best_rmse:.4f}\")\n",
    "\n",
    "# Final predictions using best_k\n",
    "final_actual, final_predicted = [], []\n",
    "\n",
    "for _, row in df_test.iterrows():\n",
    "    pred = predict_rating_itemknn(row['user_id'], row['movie_id'], best_k)\n",
    "    if not np.isnan(pred):\n",
    "        final_actual.append(row['rating'])\n",
    "        final_predicted.append(pred)\n",
    "\n",
    "final_rmse = np.sqrt(mean_squared_error(final_actual, final_predicted))\n",
    "print(f\"\\nFinal RMSE using best k={best_k}: {final_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  actual_rating  predicted_rating    model\n",
      "0      1.0       9.0            5.0          3.941185  itemknn\n",
      "1      1.0      14.0            5.0          4.465212  itemknn\n",
      "2      1.0      15.0            5.0          3.818630  itemknn\n",
      "3      1.0      18.0            4.0          3.921278  itemknn\n",
      "4      1.0      21.0            1.0          3.796338  itemknn\n",
      "\n",
      "Total predictions made by ItemKNN: 20303\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to collect prediction rows\n",
    "itemknn_preds = []\n",
    "\n",
    "# Loop through the test set and collect predictions\n",
    "for _, row in df_test.iterrows():\n",
    "    user = row['user_id']\n",
    "    movie = row['movie_id']\n",
    "    actual = row['rating']\n",
    "    \n",
    "    pred = predict_rating_itemknn(user, movie, best_k)\n",
    "    \n",
    "    if not np.isnan(pred):\n",
    "        itemknn_preds.append({\n",
    "            'user_id': user,\n",
    "            'movie_id': movie,\n",
    "            'actual_rating': actual,\n",
    "            'predicted_rating': pred,\n",
    "            'model': 'itemknn'\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_itemknn_preds = pd.DataFrame(itemknn_preds)\n",
    "\n",
    "# Quick check\n",
    "print(df_itemknn_preds.head())\n",
    "print(f\"\\nTotal predictions made by ItemKNN: {len(df_itemknn_preds)}\")\n",
    "\n",
    "# saved and used for fairness metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
